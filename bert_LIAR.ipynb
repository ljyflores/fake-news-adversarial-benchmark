{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "environment": {
      "name": "pytorch-gpu.1-7.m65",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "bert_LIAR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEXrlTZzTONe"
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "id": "cEXrlTZzTONe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzUQGNmpS-8F"
      },
      "source": [
        "!pip3 install transformers\n",
        "!cp /content/drive/MyDrive/fake-news-explainability/utils_fake_news.py ."
      ],
      "id": "IzUQGNmpS-8F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clean-insulation"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json, re\n",
        "from tqdm import tqdm_notebook\n",
        "from uuid import uuid4\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import itertools\n",
        "import os\n",
        "\n",
        "## Torch Modules\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import (\n",
        "    Dataset, \n",
        "    DataLoader,\n",
        "    TensorDataset, \n",
        "    random_split, \n",
        "    RandomSampler, \n",
        "    SequentialSampler)\n",
        "\n",
        "# Transformers\n",
        "from transformers import (\n",
        "    BertModel,\n",
        "    BertForSequenceClassification,\n",
        "    BertTokenizer,\n",
        "    RobertaForSequenceClassification,\n",
        "    RobertaTokenizer,\n",
        "    AdamW,\n",
        "    get_linear_schedule_with_warmup)\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "%run utils_fake_news.py"
      ],
      "id": "clean-insulation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQVCTufK2zZI"
      },
      "source": [
        "## Model & Training Function"
      ],
      "id": "zQVCTufK2zZI"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFk_Xt8J6bra"
      },
      "source": [
        "def train():\n",
        "    total_t0 = time.time()\n",
        "    for epoch_i in range(0, epochs):\n",
        "        \n",
        "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        print('Training...')\n",
        "\n",
        "        t0 = time.time()\n",
        "        total_train_loss = 0\n",
        "        bert_model.train()\n",
        "\n",
        "        for step, batch in enumerate(bert_train_dataloader):\n",
        "\n",
        "            # Progress update every 40 batches.\n",
        "            if step % 40 == 0 and not step == 0:\n",
        "                elapsed = format_time(time.time() - t0)\n",
        "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(bert_train_dataloader), elapsed))\n",
        "\n",
        "            # Unpack batch\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            # Zero grads\n",
        "            bert_model.zero_grad()        \n",
        "\n",
        "            # Forward pass\n",
        "            output = bert_model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask, \n",
        "                                labels=b_labels)\n",
        "            # Accumulate loss\n",
        "            total_train_loss += output[0].item()\n",
        "\n",
        "            # Backward pass\n",
        "            output[0].backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(bert_model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and take a step using the computed gradient.\n",
        "            # The bert_optimizer dictates the \"update rule\"--how the parameters are\n",
        "            # modified based on their gradients, the learning rate, etc.\n",
        "            bert_optimizer.step()\n",
        "\n",
        "            # Update the learning rate.\n",
        "            bert_scheduler.step()\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_train_loss = total_train_loss / len(bert_train_dataloader)            \n",
        "        \n",
        "        # Measure how long this epoch took.\n",
        "        training_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "        # Record all statistics from this epoch.\n",
        "        bert_training_stats.append(\n",
        "            {\n",
        "                'epoch': epoch_i + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Training Time': training_time,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "    print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "id": "zFk_Xt8J6bra",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXtHiLIT7ctT"
      },
      "source": [
        "## Load Data"
      ],
      "id": "mXtHiLIT7ctT"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoquvyV57cbU"
      },
      "source": [
        "# Run if the data has already been encoded\n",
        "# Load encoded LIAR dataset\n",
        "df_train_encode = torch.load(\"/content/drive/MyDrive/fake-news-explainability/Data/Encoded/liar/training/liar_train.pt\")"
      ],
      "id": "JoquvyV57cbU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMNdJRH97fz6"
      },
      "source": [
        "# Load data into dataloader\n",
        "batch_size = 32\n",
        "\n",
        "bert_train_dataloader = DataLoader(\n",
        "            df_train_encode,  # The training samples.\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )"
      ],
      "id": "sMNdJRH97fz6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2etwHPbK6gWV"
      },
      "source": [
        "## Training"
      ],
      "id": "2etwHPbK6gWV"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "available-coffee"
      },
      "source": [
        "# Device\n",
        "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "# BERT\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Model\n",
        "bert_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "                                                           num_labels = 2,\n",
        "                                                           output_attentions = False,\n",
        "                                                           output_hidden_states = False\n",
        "                                                          ).to(device)\n",
        "\n",
        "# Optimizer\n",
        "bert_optimizer = AdamW(bert_model.parameters(),\n",
        "                  lr = 5e-5, # args.learning_rate - default is 5e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "id": "available-coffee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duWztHOOkwRa"
      },
      "source": [
        "# Training Params\n",
        "bert_training_stats = []\n",
        "epochs = 10\n",
        "total_steps = len(bert_train_dataloader) * epochs\n",
        "\n",
        "# Learning rate scheduler.\n",
        "bert_scheduler = get_linear_schedule_with_warmup(bert_optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "id": "duWztHOOkwRa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peaceful-fashion"
      },
      "source": [
        "# Train or load pre-trained\n",
        "bert_model_path = \"/content/drive/MyDrive/fake-news-explainability/Models/liar_model2\"\n",
        "    \n",
        "if os.path.exists(bert_model_path):\n",
        "    bert_model = BertForSequenceClassification.from_pretrained(\n",
        "        bert_model_path, num_labels = 2).to(device)\n",
        "else:\n",
        "    train()\n",
        "    bert_model.save_pretrained(bert_model_path)"
      ],
      "id": "peaceful-fashion",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x76cBsq4Tti"
      },
      "source": [
        "## Accuracy"
      ],
      "id": "2x76cBsq4Tti"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPytiFpc4TV-",
        "outputId": "d2ddb447-ea1d-42c3-d91b-2371e9c2183b"
      },
      "source": [
        "# Load dataset\n",
        "# df_encode = torch.load(\"/content/drive/MyDrive/fake-news-explainability/Data/Encoded/liar/training/liar_test.pt\")\n",
        "df_encode = torch.load(\"/content/drive/MyDrive/fake-news-explainability/Data/Encoded/liar/training/liar_valid.pt\")\n",
        "\n",
        "labels = np.array([int(t[2]) for t in df_encode])\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = bert_model(df_encode.tensors[0].to(device),\n",
        "                         token_type_ids=None, \n",
        "                         attention_mask=df_encode.tensors[1].to(device),\n",
        "                         labels=df_encode.tensors[2].to(device))\n",
        "    \n",
        "# Accuracy\n",
        "print(f\"Accuracy: {flat_accuracy(outputs[1].detach().cpu().numpy(), labels)}\")"
      ],
      "id": "HPytiFpc4TV-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5864485981308412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "competent-klein"
      },
      "source": [
        "## Evaluate"
      ],
      "id": "competent-klein"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sharing-david"
      },
      "source": [
        "# Load encoded tensors\n",
        "# df_pos_encode = torch.load(\"/content/drive/MyDrive/fake-news-explainability/Data/Encoded/liar/evaluation/liar_valid_pos.pt\")\n",
        "# df_neg_encode = torch.load(\"/content/drive/MyDrive/fake-news-explainability/Data/Encoded/liar/evaluation/liar_valid_neg.pt\")\n",
        "\n",
        "# df_pos_encode = torch.load(\"/content/drive/MyDrive/fake-news-explainability/Data/Encoded/liar/evaluation/liar_test_name_orig_filtered.pt\")\n",
        "# df_neg_encode = torch.load(\"/content/drive/MyDrive/fake-news-explainability/Data/Encoded/liar/evaluation/liar_test_name_new_filtered.pt\")\n",
        "\n",
        "df_pos_encode = torch.load(\"/content/drive/MyDrive/fake-news-explainability/Data/Encoded/liar/evaluation/liar_test_polarity_orig_filtered.pt\")\n",
        "df_neg_encode = torch.load(\"/content/drive/MyDrive/fake-news-explainability/Data/Encoded/liar/evaluation/liar_test_polarity_new_filtered.pt\")\n",
        "\n",
        "# Generate predictions\n",
        "with torch.no_grad():\n",
        "    outputs_pos = bert_model(df_pos_encode.tensors[0].to(device),\n",
        "                              token_type_ids=None, \n",
        "                              attention_mask=df_pos_encode.tensors[1].to(device),\n",
        "                              labels=df_pos_encode.tensors[2].to(device))\n",
        "    outputs_neg = bert_model(df_neg_encode.tensors[0].to(device),\n",
        "                               token_type_ids=None, \n",
        "                               attention_mask=df_neg_encode.tensors[1].to(device),\n",
        "                               labels=df_neg_encode.tensors[2].to(device))"
      ],
      "id": "sharing-david",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXpqqsUc_mFG"
      },
      "source": [
        "## Metrics"
      ],
      "id": "NXpqqsUc_mFG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE5t5CHxqIA7",
        "outputId": "ef973ebf-71ee-402f-d60c-b95d1ce40aa9"
      },
      "source": [
        "# Percent Labels Flipped\n",
        "cf_matrix = confusion_matrix(torch.argmax(outputs_pos[1].cpu(), axis=1), \n",
        "                             torch.argmax(outputs_neg[1].cpu(), axis=1))\n",
        "print(f\"Labels Flipped: {cf_matrix[0,1]+cf_matrix[1,0]} of {np.sum(cf_matrix)} ({round(100*(cf_matrix[0,1]+cf_matrix[1,0])/np.sum(cf_matrix),4)}%)\")"
      ],
      "id": "ZE5t5CHxqIA7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels Flipped: 0 of 14 (0.0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukNjnIACo-b3",
        "outputId": "1641796b-0721-4570-8a08-6adfe7f4bb2b"
      },
      "source": [
        "# Average Probability Change\n",
        "m = nn.Softmax(dim=1)\n",
        "delta_lst = m(outputs_neg['logits'])[:,1]-m(outputs_pos['logits'])[:,1]\n",
        "print(f\"Average Change: {round(float(torch.mean(delta_lst)),4)} ({round(float(torch.std(delta_lst)),4)})\")"
      ],
      "id": "ukNjnIACo-b3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Change: 0.0267 (0.0644)\n"
          ]
        }
      ]
    }
  ]
}
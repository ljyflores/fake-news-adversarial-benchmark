{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "negation_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjrkRDZp9RDy"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKaXT4-skH6J"
      },
      "source": [
        "!pip3 install transformers\n",
        "!cp /content/drive/MyDrive/fake-news-explainability/utils_fake_news.py ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bjmy5varkD4d"
      },
      "source": [
        "%run utils_fake_news.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn6yXlYHVWqR"
      },
      "source": [
        "negate_dict = {\"isn't\":\"is\",\n",
        "    \"isn\\\\'t\":\"is\",\n",
        "    \"is not \":\"is \",\n",
        "    \"is \":\"is not \",\n",
        "    \"didn't\":\"did\",\n",
        "    \"didn\\\\'t\":\"did\",\n",
        "    \"did not \":\"did\",\n",
        "    \"does not have\":\"has\",\n",
        "    \"doesn't have\":\"has\",\n",
        "    \"doesn\\\\'t have\":\"has\",\n",
        "    \"has \":\"does not have \",\n",
        "    \"shouldn't\":\"should\",\n",
        "    \"shouldn\\\\'t\":\"should\",\n",
        "    \"should not\":\"should\",\n",
        "    \"should\":\"should not\",\n",
        "    \"wouldn't\":\"would\",\n",
        "    \"wouldn\\\\'t\":\"would\",\n",
        "    \"would not\":\"would\",\n",
        "    \"would\":\"would not\",\n",
        "    \"mustn't\":\"must\",\n",
        "    \"mustn\\\\'t\":\"must\",\n",
        "    \"must not\":\"must\",\n",
        "    \"must \":\"must not \",\n",
        "    \"can't\":\"can\",\n",
        "    \"can\\\\'t\":\"can\",\n",
        "    \"cannot\":\"can\",\n",
        "    \" can \":\" cannot \"}\n",
        "\n",
        "IRREGULAR_ES_VERB_ENDINGS = [\"ss\", \"x\", \"ch\", \"sh\", \"o\"]\n",
        "\n",
        "def negate(sentence):\n",
        "\n",
        "  for key in negate_dict.keys():\n",
        "    if sentence.find(key) > -1:\n",
        "      return sentence.replace(key, negate_dict[key])\n",
        "\n",
        "  # doesn't work -> works\n",
        "  doesnt_regex = r'(doesn\\'t|doesn\\\\\\'t|does not) (?P<verb>\\w+)'\n",
        "\n",
        "  if re.search(doesnt_regex, sentence):\n",
        "    return re.sub(doesnt_regex, replace_doesnt, sentence, 1)\n",
        "\n",
        "  return None\n",
        "\n",
        "def __is_consonant(letter):\n",
        "  return letter not in ['a', 'e', 'i', 'o', 'u', 'y']\n",
        "\n",
        "def replace_doesnt(matchobj):\n",
        "  verb = matchobj.group(2)\n",
        "\n",
        "  if verb.endswith(\"y\") and __is_consonant(verb[-2]):\n",
        "    return \"{0}ies\".format(verb[0:-1])\n",
        "\n",
        "  for ending in IRREGULAR_ES_VERB_ENDINGS:\n",
        "    if verb.endswith(ending):\n",
        "      return \"{0}es\".format(verb)\n",
        "\n",
        "  return \"{0}s\".format(verb)\n",
        "\n",
        "def replace_verb(matchobj):\n",
        "  subject = matchobj.group(1)\n",
        "  verb = matchobj.group(2)\n",
        "  whitespace = matchobj.group(3)\n",
        "\n",
        "  # flies -> fly, but not die -> dy\n",
        "  if verb.endswith(\"ie\") and len(verb) > 3:\n",
        "    verb = \"{0}y\".format(verb[0:-2])\n",
        "\n",
        "  # stresses -> stress\n",
        "  for ending in IRREGULAR_ES_VERB_ENDINGS:\n",
        "    if verb.endswith(\"{0}e\".format(ending)):\n",
        "      verb = verb[0:-1]\n",
        "\n",
        "  return \"{0}does not {1}{2}\".format(subject, verb, whitespace)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA1ZYkt3W4KE"
      },
      "source": [
        "### Fake News Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rT5nNLcWkUk"
      },
      "source": [
        "# Read in data\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/fake-news-explainability/Data/Raw/fake_news_train.csv\")\n",
        "df = df.rename(columns={'title':'statement'})\n",
        "df = df.dropna(subset=['statement']).reset_index(drop=True)\n",
        "df = df.drop(['author','text'], axis=1)\n",
        "\n",
        "# Clean and negate\n",
        "df['statement'] = df['statement'].apply(lambda x: x.lower().replace('’',\"'\"))\n",
        "df_neg = df.copy()\n",
        "df_neg['statement'] = df_neg['statement'].apply(negate)\n",
        "\n",
        "df_neg = df_neg.loc[~df_neg.statement.isnull()]\n",
        "df_pos = df.loc[df_neg.index].reset_index(drop=True)\n",
        "df_neg = df_neg.reset_index(drop=True)\n",
        "\n",
        "# Relabel\n",
        "df_neg['label'] = df_neg['label'].apply(lambda x: 0 if x==1 else 1)\n",
        "\n",
        "# Save encoded versions for FakeBERT\n",
        "# torch.save(encode_dataframe(df['statement'], df['label']),\n",
        "#            '/content/drive/MyDrive/fake-news-explainability/Data/Encoded/fake_news/training/fake_news.pt')\n",
        "# torch.save(encode_dataframe(df_pos['statement'], df_pos['label']),\n",
        "#            '/content/drive/MyDrive/fake-news-explainability/Data/Encoded/fake_news/evaluation/fake_news_pos.pt')\n",
        "# torch.save(encode_dataframe(df_neg['statement'], df_neg['label']),\n",
        "#            '/content/drive/MyDrive/fake-news-explainability/Data/Encoded/fake_news/evaluation/fake_news_neg.pt')\n",
        "\n",
        "# Save CSV versions for FakeBERT TF-IDF\n",
        "df_pos.to_csv('/content/drive/MyDrive/fake-news-explainability/Data/Encoded/fake_news/evaluation/fake_news_pos.csv', index=False)\n",
        "df_neg.to_csv('/content/drive/MyDrive/fake-news-explainability/Data/Encoded/fake_news/evaluation/fake_news_neg.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6uGtu8VXpzj"
      },
      "source": [
        "### LIAR Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3zciRdoiFoB"
      },
      "source": [
        "# Read in train data\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/fake-news-explainability/Data/Raw/liar_train.tsv\", \n",
        "                 delimiter='\\t', \n",
        "                 header=None)\n",
        "df.columns = ['ID','label','statement','subject','speaker',\n",
        "              'job_title','state','party','barely_true_count',\n",
        "              'false_count','half_true_count','mostly_true_count',\n",
        "              'pants_on_fire_count','context']\n",
        "df = df.dropna(subset=['statement']).reset_index(drop=True)\n",
        "df = df[['ID','statement','label']]\n",
        "\n",
        "# Label\n",
        "liar_encode = {'barely-true':1, 'false':1, 'half-true':1, \n",
        "               'mostly-true':0, 'pants-fire':0, 'true':0}\n",
        "df['label'] = df['label'].apply(lambda x: liar_encode[x])\n",
        "\n",
        "# Save\n",
        "torch.save(encode_dataframe(df['statement'], df['label']),\n",
        "           '/content/drive/MyDrive/fake-news-explainability/Data/Encoded/liar/training/liar_train.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiuKjkHHX5Ul"
      },
      "source": [
        "# Read in test data\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/fake-news-explainability/Data/Raw/liar_test.tsv\", \n",
        "                 delimiter='\\t', \n",
        "                 header=None)\n",
        "df.columns = ['ID','label','statement','subject','speaker',\n",
        "              'job_title','state','party','barely_true_count',\n",
        "              'false_count','half_true_count','mostly_true_count',\n",
        "              'pants_on_fire_count','context']\n",
        "df = df.dropna(subset=['statement']).reset_index(drop=True)\n",
        "df = df[['ID','statement','label']]\n",
        "\n",
        "# Label\n",
        "liar_encode = {'barely-true':1, 'false':1, 'pants-fire':1, \n",
        "               'half-true':0, 'mostly-true':0, 'true':0}\n",
        "df['label'] = df['label'].apply(lambda x: liar_encode[x])\n",
        "\n",
        "# Clean and negate\n",
        "df['statement'] = df['statement'].apply(lambda x: x.lower().replace('’',\"'\"))\n",
        "df_neg = df.copy()\n",
        "df_neg['statement'] = df_neg['statement'].apply(negate)\n",
        "\n",
        "df_neg = df_neg.loc[~df_neg.statement.isnull()]\n",
        "df_pos = df.loc[df_neg.index].reset_index(drop=True)\n",
        "df_neg = df_neg.reset_index(drop=True)\n",
        "\n",
        "# Relabel\n",
        "df_neg['label'] = df_neg['label'].apply(lambda x: 0 if x==1 else 1)\n",
        "\n",
        "# Save\n",
        "torch.save(encode_dataframe(df['statement'], df['label']),\n",
        "           '/content/drive/MyDrive/fake-news-explainability/Data/Encoded/liar/training/liar_test.pt')\n",
        "torch.save(encode_dataframe(df_pos['statement'], df_pos['label']),\n",
        "           '/content/drive/MyDrive/fake-news-explainability/Data/Encoded/liar/evaluation/liar_test_pos.pt')\n",
        "torch.save(encode_dataframe(df_neg['statement'], df_neg['label']),\n",
        "           '/content/drive/MyDrive/fake-news-explainability/Data/Encoded/liar/evaluation/liar_test_neg.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQZK0SPMYmjF"
      },
      "source": [
        "# Read in validation data\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/fake-news-explainability/Data/Raw/liar_valid.tsv\", \n",
        "                 delimiter='\\t', \n",
        "                 header=None)\n",
        "df.columns = ['ID','label','statement','subject','speaker',\n",
        "              'job_title','state','party','barely_true_count',\n",
        "              'false_count','half_true_count','mostly_true_count',\n",
        "              'pants_on_fire_count','context']\n",
        "df = df.dropna(subset=['statement']).reset_index(drop=True)\n",
        "df = df[['ID','statement','label']]\n",
        "\n",
        "# Label\n",
        "liar_encode = {'barely-true':1, 'false':1, 'half-true':1, \n",
        "               'mostly-true':0, 'pants-fire':0, 'true':0}\n",
        "df['label'] = df['label'].apply(lambda x: liar_encode[x])\n",
        "\n",
        "# Clean and negate\n",
        "df['statement'] = df['statement'].apply(lambda x: x.lower().replace('’',\"'\"))\n",
        "df_neg = df.copy()\n",
        "df_neg['statement'] = df_neg['statement'].apply(negate)\n",
        "\n",
        "df_neg = df_neg.loc[~df_neg.statement.isnull()]\n",
        "df_pos = df.loc[df_neg.index].reset_index(drop=True)\n",
        "df_neg = df_neg.reset_index(drop=True)\n",
        "\n",
        "# Relabel\n",
        "df_neg['label'] = df_neg['label'].apply(lambda x: 0 if x==1 else 1)\n",
        "\n",
        "# Save\n",
        "torch.save(encode_dataframe(df['statement'], df['label']),\n",
        "           '/content/drive/MyDrive/fake-news-explainability/Data/Encoded/liar/training/liar_valid.pt')\n",
        "torch.save(encode_dataframe(df_pos['statement'], df_pos['label']),\n",
        "           '/content/drive/MyDrive/fake-news-explainability/Data/Encoded/liar/evaluation/liar_valid_pos.pt')\n",
        "torch.save(encode_dataframe(df_neg['statement'], df_neg['label']),\n",
        "           '/content/drive/MyDrive/fake-news-explainability/Data/Encoded/liar/evaluation/liar_valid_neg.pt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"fakebert.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"nVqe1h6QTeqU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622948726605,"user_tz":-480,"elapsed":353,"user":{"displayName":"Lj Flores","photoUrl":"","userId":"11095487892395270199"}},"outputId":"458a3c0b-f99a-4edf-a26c-875859815b99"},"source":["from google.colab import drive, files\n","drive.mount('/content/drive')"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a4-8mzRfTenc","executionInfo":{"status":"ok","timestamp":1622948730761,"user_tz":-480,"elapsed":7,"user":{"displayName":"Lj Flores","photoUrl":"","userId":"11095487892395270199"}}},"source":["!pip3 install transformers\n","!cp /content/drive/MyDrive/fake-news-explainability/utils_fake_news.py ."],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"p1qS7W-lTek4","executionInfo":{"status":"ok","timestamp":1622949183894,"user_tz":-480,"elapsed":1924,"user":{"displayName":"Lj Flores","photoUrl":"","userId":"11095487892395270199"}}},"source":["import pandas as pd\n","import numpy as np\n","import json, re\n","from tqdm import tqdm_notebook\n","from uuid import uuid4\n","import time\n","import datetime\n","import random\n","import itertools\n","\n","## Torch Modules\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from torch.utils.data import (\n","    Dataset, \n","    DataLoader,\n","    TensorDataset, \n","    random_split, \n","    RandomSampler, \n","    SequentialSampler)\n","\n","# Transformers\n","from transformers import (\n","    BertForSequenceClassification,\n","    BertTokenizer,\n","    RobertaForSequenceClassification,\n","    RobertaTokenizer,\n","    AdamW,\n","    get_linear_schedule_with_warmup)\n","\n","# Visualization\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","\n","%run utils_fake_news.py\n","\n","# Device\n","device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device(\"cpu\")"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0S9xnuy219fZ"},"source":["## Preprocess & Encode Data"]},{"cell_type":"code","metadata":{"id":"pbg-euxIESKb","executionInfo":{"status":"ok","timestamp":1622947885744,"user_tz":-480,"elapsed":9810,"user":{"displayName":"Lj Flores","photoUrl":"","userId":"11095487892395270199"}}},"source":["# Load the Fake-News Kaggle dataset\n","df_pos = pd.read_csv(\"/content/drive/MyDrive/fake-news-explainability/Data/Negation_Task/fake_news_positive.csv\")\n","df_neg = pd.read_csv(\"/content/drive/MyDrive/fake-news-explainability/Data/Negation_Task/fake_news_negative.csv\")\n","\n","# Relabel target\n","df_pos['target'] = df_pos['label']\n","df_neg['target'] = df_neg['label'].apply(lambda x: 0 if x==1 else 1)\n","df_train = df_pos.append(df_neg).reset_index(drop=True)\n","\n","# Encode dataframes\n","df_train_encode = encode_dataframe(df_train['text'], df_train['target'])\n","\n","torch.save(df_train_encode,\n","           \"/content/drive/MyDrive/fake-news-explainability/Data/fake_news_encoded_negated.pt\")"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aWKDP6yz2DI9"},"source":["## Model & Training Function"]},{"cell_type":"code","metadata":{"id":"4bBYr4RA2CrJ","executionInfo":{"status":"ok","timestamp":1622948101417,"user_tz":-480,"elapsed":505,"user":{"displayName":"Lj Flores","photoUrl":"","userId":"11095487892395270199"}}},"source":["import torch.nn as nn\n","from transformers import AutoModel\n","class FakeBERT(nn.Module):\n","    def __init__(self):\n","        super(FakeBERT, self).__init__()\n","        \n","        self.base_model = AutoModel.from_pretrained('bert-base-uncased')\n","\n","        # Layer 1: Conv1D + Maxpool\n","        self.conv_1 = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=3, stride=1)\n","        self.sigm_1 = nn.ReLU()\n","        self.pool_1 = nn.MaxPool1d(kernel_size=5, stride=5)\n","        \n","        # Layer 6: Fully Connected Layer \n","        self.full_6 = nn.Linear(153,32)\n","        self.sigm_6 = nn.Sigmoid()\n","        \n","        # Layer 7: Fully Connected Layer \n","        self.full_7 = nn.Linear(32,2)\n","        self.soft_7 = nn.Softmax()\n","\n","    def forward(self, input_ids, attn_mask):\n","        bert_output = self.base_model(input_ids, attention_mask=attn_mask)\n","        bert_output = bert_output['pooler_output'].unsqueeze(1)\n","        bert_perturb = 0.1*torch.rand(768).to(device)\n","        bert_output = bert_output + bert_perturb\n","        outputs = self.pool_1(self.sigm_1(self.conv_1(bert_output)))\n","        outputs = self.sigm_6(self.full_6(outputs))\n","        outputs = self.soft_7(self.full_7(outputs))\n","        return outputs, bert_output\n","\n","def train():\n","    total_t0 = time.time()\n","    for epoch_i in range(0, epochs):\n","        \n","        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","        print('Training...')\n","\n","        t0 = time.time()\n","        total_train_loss = 0\n","        bert_model.train()\n","\n","        for step, batch in enumerate(bert_train_dataloader):\n","\n","            # Progress update every 40 batches.\n","            if step % 40 == 0 and not step == 0:\n","                elapsed = format_time(time.time() - t0)\n","                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(bert_train_dataloader), elapsed))\n","\n","            # Unpack batch\n","            b_input_ids = batch[0].to(device)\n","            b_input_mask = batch[1].to(device)\n","            b_labels = batch[2].to(device)\n","\n","            # Zero grads\n","            bert_model.zero_grad()        \n","\n","            # Forward pass\n","            output, bert_output = bert_model(b_input_ids, b_input_mask)\n","            \n","            # Accumulate loss\n","            loss = loss_func(output.squeeze(1), b_labels)\n","            print(loss.detach())\n","\n","            # Backpropagate\n","            loss.backward()\n","\n","            # Clip the norm of the gradients to 1.0.\n","            # This is to help prevent the \"exploding gradients\" problem.\n","            torch.nn.utils.clip_grad_norm_(bert_model.parameters(), 1.0)\n","\n","            # Update parameters and take a step using the computed gradient.\n","            # The bert_optimizer dictates the \"update rule\"--how the parameters are\n","            # modified based on their gradients, the learning rate, etc.\n","            bert_optimizer.step()\n","\n","            # Update the learning rate.\n","            bert_scheduler.step()\n","\n","        # Calculate the average loss over all of the batches.\n","        avg_train_loss = total_train_loss / len(bert_train_dataloader)            \n","        \n","        # Measure how long this epoch took.\n","        training_time = format_time(time.time() - t0)\n","\n","        print(\"\")\n","        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","        print(\"  Training epoch took: {:}\".format(training_time))\n","\n","        # Record all statistics from this epoch.\n","        bert_training_stats.append(\n","            {\n","                'epoch': epoch_i + 1,\n","                'Training Loss': avg_train_loss,\n","                # 'Valid. Loss': avg_val_loss,\n","                # 'Valid. Accur.': avg_val_accuracy,\n","                'Training Time': training_time,\n","                # 'Validation Time': validation_time\n","            }\n","        )\n","\n","    print(\"\")\n","    print(\"Training complete!\")\n","\n","    print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eFptuf6I7oFC"},"source":["## Load Data"]},{"cell_type":"code","metadata":{"id":"BYWfkdPw7n52"},"source":["# Run if the data has already been encoded\n","# Load encoded Fake-News Kaggle dataset\n","df_train_encode = torch.load(\"/content/drive/MyDrive/fake-news-explainability/Data/fake_news_pos_encoded.pt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rn4E6EnF7nuY"},"source":["# Load data into dataloader\n","batch_size = 32\n","bert_train_dataloader = DataLoader(\n","    df_train_encode,  # The training samples.\n","    batch_size = batch_size # Trains with this batch size.\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9a-6wuweTwDo"},"source":["## Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qTA3a85IDGYM","executionInfo":{"status":"ok","timestamp":1622525607709,"user_tz":-480,"elapsed":2256,"user":{"displayName":"Lorenzo Flores","photoUrl":"","userId":"01486192851255545065"}},"outputId":"652d26e0-e76e-4bc5-9298-98030adb3ad0"},"source":["# BERT\n","bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","\n","# Model\n","bert_model = FakeBERT().to(device)\n","\n","# Optimizer\n","bert_optimizer = AdamW(bert_model.parameters(),\n","                  lr = 5e-5, # args.learning_rate - default is 5e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )\n","\n","# Training Params\n","bert_training_stats = []\n","epochs = 2\n","total_steps = len(bert_train_dataloader) * epochs\n","loss_func = nn.CrossEntropyLoss()\n","\n","# Learning rate scheduler.\n","bert_scheduler = get_linear_schedule_with_warmup(bert_optimizer, \n","                                                 num_warmup_steps = 0, # Default value in run_glue.py\n","                                                 num_training_steps = total_steps)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"FrEft0thUO03"},"source":["# Train\n","train()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o04bpssnUkXG"},"source":["# Save model\n","torch.save(bert_model.state_dict(),\n","           \"/content/drive/MyDrive/fake-news-explainability/Models/bert_model_fake_news_perturbation_kaggle\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nqa-BzdNUDrY"},"source":["## Evaluate"]},{"cell_type":"code","metadata":{"id":"eQmZJSLx73hJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622948751693,"user_tz":-480,"elapsed":4833,"user":{"displayName":"Lj Flores","photoUrl":"","userId":"11095487892395270199"}},"outputId":"2430e858-4f3a-4cbb-e580-7f1662efeab8"},"source":["# Load model if hasn't been trained\n","bert_model = FakeBERT().to(device)\n","bert_model.load_state_dict(torch.load(\n","    \"/content/drive/MyDrive/fake-news-explainability/Models/bert_model_fake_news_kaggle\"\n","    ))\n","\n","# BERT\n","bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qbnZFGfQ80Au","executionInfo":{"status":"ok","timestamp":1622948751698,"user_tz":-480,"elapsed":32,"user":{"displayName":"Lj Flores","photoUrl":"","userId":"11095487892395270199"}}},"source":["# Load encoded tensors\n","df_pos_encode = torch.load(\"/content/drive/MyDrive/fake-news-explainability/Data/Encoded/fake_news/evaluation/fake_news_pos_encoded.pt\")\n","df_neg_encode = torch.load(\"/content/drive/MyDrive/fake-news-explainability/Data/Encoded/fake_news/evaluation/fake_news_neg_encoded.pt\")"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"4qgPtWg6Rehf","executionInfo":{"status":"ok","timestamp":1622948752968,"user_tz":-480,"elapsed":6,"user":{"displayName":"Lj Flores","photoUrl":"","userId":"11095487892395270199"}}},"source":["# Load data into dataloader\n","batch_size = 32\n","bert_pos_dataloader = DataLoader(df_pos_encode, batch_size = batch_size)\n","bert_neg_dataloader = DataLoader(df_neg_encode, batch_size = batch_size)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gD6Yy3cLRuBp","executionInfo":{"status":"ok","timestamp":1622949045967,"user_tz":-480,"elapsed":285277,"user":{"displayName":"Lj Flores","photoUrl":"","userId":"11095487892395270199"}},"outputId":"9f7bce28-b288-47f7-c126-488c396976ab"},"source":["# Generate predictions\n","# Can't input everything directly due to RAM issues\n","outputs_pos = []\n","outputs_neg = []\n","with torch.no_grad():\n","    for step, batch in enumerate(bert_pos_dataloader):\n","        # Unpack batch\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Forward pass\n","        output = bert_model(b_input_ids, b_input_mask)\n","        outputs_pos.append(output[0])\n","        \n","    for step, batch in enumerate(bert_neg_dataloader):\n","        # Unpack batch\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Forward pass\n","        output = bert_model(b_input_ids, b_input_mask)\n","        outputs_neg.append(output[0])\n","        \n","# Stack outputs\n","outputs_pos = torch.vstack(outputs_pos).squeeze(1)\n","outputs_neg = torch.vstack(outputs_neg).squeeze(1)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"NJoDmN0N5VYJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622949252493,"user_tz":-480,"elapsed":483,"user":{"displayName":"Lj Flores","photoUrl":"","userId":"11095487892395270199"}},"outputId":"f955f154-1b1e-4885-9b91-cece9cb43e6a"},"source":["# Positive statement accuracy\n","print(f\"Positive Class Acc: {flat_accuracy(outputs_pos.detach().cpu().numpy(), df_pos_encode.tensors[2].to('cpu').numpy())}\")\n","\n","# Negative statement accuracy\n","print(f\"Negative Class Acc: {flat_accuracy(outputs_neg.detach().cpu().numpy(), df_neg_encode.tensors[2].to('cpu').numpy())}\")"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Positive Class Acc: 0.9930048189025338\n","Negative Class Acc: 0.007357894191408881\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xXoy6tHa92Fp"},"source":["## Results Log\n","* FakeBERT, Trained on positive and negative classes\n","  * Result on positive/negative: tensor(0.9990)\n","  * Result on fake-news dataset: ???\n","\n"]},{"cell_type":"markdown","metadata":{"id":"AneCIlz1AWOt"},"source":["## Negation"]},{"cell_type":"code","metadata":{"id":"4Ib6MvgQAcs-","colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"status":"ok","timestamp":1622949322095,"user_tz":-480,"elapsed":373,"user":{"displayName":"Lj Flores","photoUrl":"","userId":"11095487892395270199"}},"outputId":"7fc907b6-d065-4489-f720-cc63d5fb6bb9"},"source":["# Confusion matrix\n","cf_matrix = confusion_matrix(torch.argmax(outputs_pos.cpu(), axis=1), \n","                             torch.argmax(outputs_neg.cpu(), axis=1))\n","sns.heatmap(cf_matrix, annot=True)"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f0cc2feb150>"]},"metadata":{"tags":[]},"execution_count":28},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"rGOA3KRlUViI"},"source":[""],"execution_count":null,"outputs":[]}]}